<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Semantic Image Synthesis with Unconditional Generator">
  <meta name="keywords" content="Semantic Image Synthesis, GAN, SIS with Unconditional G">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>SIS with Unconditional Generator</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <!-- <link rel="icon" href="./static/images/favicon.svg"> -->

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Semantic Image Synthesis with Unconditional Generator</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              Jungwoo Chae</a><sup>*1,2</sup>,</span>
            <span class="author-block">
              Hyunin Cho</a><sup>*1</sup>,</span>
            <span class="author-block">
              Sooyeon Go<sup>1</sup>,</span>
            <span class="author-block">
              Kyungmook Choi<sup>1</sup>,</span>
            <span class="author-block">
              Youngjung Uh<sup>2</sup>,</span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Yonsei University,</span>
            <span class="author-block"><sup>2</sup>LG CNS AI Research</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2402.14395"
                  class="external-link button is-normal is-rounded custom-button-color">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-4" style="margin-bottom: -10px; color: #012b62ca;">Abstract</h2>
    <hr class="thick-line">
      <p>
        Semantic image synthesis (SIS) aims to generate realistic images that match given semantic masks. 
        Despite recent advances allowing high-quality results and precise spatial control, they require a massive semantic segmentation dataset for training the models. 
        Instead, we propose to employ a pre-trained unconditional generator and rearrange its feature maps according to proxy masks. 
        The proxy masks are prepared from the feature maps of random samples in the generator by simple clustering. 
        The feature rearranger learns to rearrange original feature maps to match the shape of the proxy masks that are either from the original sample itself or from random samples. 
        Then we introduce a semantic mapper that produces the proxy masks from various input conditions including semantic masks. 
        Our method is versatile across various applications such as free-form spatial editing of real images, sketch-to-photo, and even scribble-to-photo. 
        Experiments validate advantages of our method on a range of datasets: human faces, animal faces, and buildings.
        
      </p>
    </div>
  </div>
</section>

<style>
  .thick-line {
    border: 0;
    height: 4px; /* Adjust the thickness as needed */
    background: #012b62ca;
    margin: 20px 0; /* Adjust the margin as needed */
  }
</style>
<style>
  .paragraph-background {
    background-color: #f0f0f0; /* Change the background color as needed */
    padding: 20px; /* Add padding for better visual appeal, adjust as needed */
  }
</style>
<style>
  .custom-button-color {
    background-color: #012b62ca;
    color: #fff; /* Set text color to white or another contrasting color */
  }
</style>


<!-- Motivation -->
<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-4" style="margin-bottom: -10px; color: #012b62ca;">Motivation</h2>
    <hr class="thick-line">
    <div class="columns">
      <div class="column">
        <div class="content">
          <p>
            The intermediate feature maps of the generator contain the semantics of the resulting image.
            Therefore, editing these feature maps will result in a corresponding change to the resulting image.  
          </p>
          <!-- Adjust the width of the image by adding a style attribute -->
          <img src="./static/images_ours/editing_in_style.png"
              class="interpolation-image"
              alt="Interpolate start reference image."
              style="max-width: 100%; height: auto;"/>
        </div>
      </div>
      <!-- Add a dividing line between the two columns -->
      <div class="column" style="border-left: 1px solid #012b62ca; padding-left: 20px;">
        <div class="columns is-centered">
          <div class="column content">
            <p style="margin-bottom: 50px;">
              Feature maps have spatial semantics that can create a semantic mask by clustering feature maps.
              We use a proxy mask as a paired annotation.
            </p>
            <!-- Adjust the width of the image by adding a style attribute -->
            <img src="./static/images_ours/rearrangement.png"
                class="interpolation-image"
                alt="Interpolate start reference image."
                style="max-width: 100%; height: auto;"/>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-4" style="margin-bottom: -10px; color: #012b62ca;">Proposed Method</h2>
    <hr class="thick-line">
    <p style="margin-bottom: 20px;">
      We introduce a novel method for semantic image synthesis: rearranging feature maps of a pretrained unconditional generator according to given semantic masks. 
      We break down our problem into two sub-problems to accomplish our objectives: rearranging and preparing supervision for the rearrangement.  
    </p>
    <p style="margin-bottom: 20px;">
      First, we design a rearranger that produces output feature maps according to input conditions by rearranging feature maps through an attention mechanism. 
    </p>
    <p style="margin-bottom: 40px;">
      Second, we prepare randomly generated samples, their feature maps, and spatial clustering. 
      The rearranger learns to rearrange the feature maps of one sample to match the semantic spatial arrangement of the other sample. 
      However, a semantic gap may arise when the generator receives an input mask. 
      This gap is due to the discrepancy between the input segmentation mask and the proxy mask. 
      The proxy masks are the arrangement of feature maps derived from the feature maps in the generator through simple clustering. 
      We solve this perception difference by training a semantic mapper to convert an input mask to a proxy mask.
    </p>
    <div class="columns">
      <div class="column">
        <div class="content">
          <h4 class="title is-6" style="color: #012b62ca;">Rearranger</h4>
          <!-- Adjust the width of the image by adding a style attribute -->
          <img src="./static/images_ours/Rearranger.png"
              class="interpolation-image"
              alt="Interpolate start reference image."
              style="max-width: 100%; height: auto;"/>
        </div>
      </div>
      <!-- Add a dividing line between the two columns -->
      <div class="column" style="border-left: 1px solid #012b62ca; padding-left: 20px;">
        <h4 class="title is-6" style="color: #012b62ca;">Semantic Mapper</h4>
        <div class="columns is-centered">
          <div class="column content">
            <p style="margin-bottom: 30px;">
            </p>
            <!-- Adjust the width of the image by adding a style attribute -->
            <img src="./static/images_ours/mapper.png"
                class="interpolation-image"
                alt="Interpolate start reference image."
                style="max-width: 100%; height: auto;"/>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-4" style="margin-bottom: -10px; color: #012b62ca;">Inference</h2>
    <hr class="thick-line">
    <div class="columns vertical_center">
      <div class="column is-two-sixths">
        <div class="columns">
          <div class="column">
            <figure>
              <video poster="" autoplay controls muted loop playsinline height="100%">
                  <source src="./static/videos_ours/inference.mp4"
                          type="video/mp4">
                </video>
            </figure>
          </div>
        </div>
      </div>
    </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-4" style="margin-bottom: -10px; color: #012b62ca;">Comparison with Competitors</h2>
    <hr class="thick-line">
    <h3 class="title is-5" style="color: #012b62ca;">Qualitative Comparison with a Few-shot Method</h3>
    <div class="columns vertical_center">
      <div class="column is-two-sixths">
        <div class="columns">
          <div class="column">
            <figure>
              <img src="./static/images_ours/vs_few.png" class="interpolation-image" alt="Comparison with a Few-shot Method"/>
            </figure>
          </div>
        </div>
      </div>
    </div>

    <h3 class="title is-5" style="color: #012b62ca;">Qualitative Comparison with Supervised Methods</h3>
    <div class="columns vertical_center">
      <div class="column is-two-sixths">
        <div class="columns">
          <figure>
            <img src="./static/images_ours/vs_sup.png" class="interpolation-image" alt="Comparison with Supervised Methods" width="1000"/>
          </figure>
        </div>
      </div>
    </div>

    <h3 class="title is-5" style="color: #012b62ca;">Quantitative Results</h3>
    <div class="columns vertical_center">
      <div class="column is-two-sixths">
        <div class="content">
          <h4 class="title is-6" style="color: #012b62ca;">Quantitative Comparision with a Few-Shot Method</h4>
          <img src="./static/images_ours/qual_few.png" class="qual-image-few" alt="Interpolate start reference image."/>
        </div>
      </div>
      <div class="column" style="border-left: 1px solid #012b62ca; padding-left: 40px;">
        <h4 class="title is-6" style="color: #012b62ca;">Quantitative Comparison with Supervised Methods</h4>
        <div class="columns is-centered">
          <div class="column content">
            <img src="./static/images_ours/qual_sup.png" class="qual-image-sup" alt="Interpolate start reference image."/>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-4" style="margin-bottom: -10px; color: #012b62ca;">Applications</h2>
    <hr class="thick-line">
    <h3 class="title is-5" style="color: #012b62ca;">Application 1 - Free-Form Image Manipulation</h3>
    <p style="margin-bottom: 5px;">
      We demonstrate the flexibility of our proposed method in enabling free-form image manipulation. 
      Our approach highlights its capability of handling masks that differ significantly from typical training distributions, such as large pointy ears and corn head.
    </p>
    <div class="columns vertical_center">
      <div class="column is-two-sixths">
        <div class="columns">
          <div class="column">
            <figure>
              <img src="./static/images_ours/Free-form.png"/>
            </figure>
          </div>
        </div>
      </div>
    </div>

    <h3 class="title is-5" style="color: #012b62ca;">Application 2 - Image Generation with Multiple Conditions</h3>
    <p style="margin-bottom: 40px;">
      To show the versatility of our method, we present images generated under various conditions of user sketch, HED and depth map.
    </p>
    <h4 class="title is-6" style="color: #012b62ca;">
          AFHQ Cat Results with Sketch Conditions
    </h4>
    <div class="columns vertical_center">
      <div class="column is-two-sixths">
        <div class="columns">
          <div class="column">
            <figure>
              <img src="./static/images_ours/sketch_cat.png" width="2000"/>
            </figure>
          </div>
        </div>
      </div>
    </div>
    <h4 class="title is-6" style="color: #012b62ca;">
          LSUN Church Results with Sketch Conditions
    </h4>
    <div class="columns vertical_center">
      <div class="column is-two-sixths">
        <div class="columns">
          <div class="column">
            <figure>
              <img src="./static/images_ours/sketch_church.png" width="2000"/>
            </figure>
          </div>
        </div>
      </div>
    </div>
    <h4 class="title is-6" style="color: #012b62ca;">
          FFHQ Results with HED Conditions
    </h4>
    <div class="columns vertical_center">
      <div class="column is-two-sixths">
        <div class="columns">
          <div class="column">
            <figure>
              <img src="./static/images_ours/ffhq_hed.png" width="2000"/>
            </figure>
          </div>
        </div>
      </div>
    </div>
    <h4 class="title is-6" style="color: #012b62ca;">
          LSUN Bedroom Results with Depth Conditions
    </h4>
    <div class="columns vertical_center">
      <div class="column is-two-sixths">
        <div class="columns">
          <div class="column">
            <figure>
              <img src="./static/images_ours/bedroom_depth.png" width="2000"/>
            </figure>
          </div>
        </div>
      </div>
    </div>

    <h3 class="title is-5" style="color: #012b62ca;">Application 3 - Exemplar-Guided Image Generation</h3>
    <p style="margin-bottom: 5px;">
      Beyond the specified conditions, our model produces an output image that has a similar structure to a provided sample. 
      The process can be done by obtaining the proxy mask of the inverted provided sample.
    </p>
    <div class="columns vertical_center">
      <div class="column is-two-sixths">
        <div class="columns">
          <div class="column">
            <figure>
              <img src="./static/images_ours/exemplarpng.png"/>
            </figure>
          </div>
        </div>
      </div>
    </div>

  </div>
</section>



<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-10">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            We borrow the website template from <a
              href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
